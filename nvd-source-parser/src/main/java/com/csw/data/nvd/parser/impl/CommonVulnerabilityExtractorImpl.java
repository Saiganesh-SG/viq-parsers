package com.csw.data.nvd.parser.impl;

import java.io.IOException;
import java.sql.Timestamp;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.TimeUnit;

import org.json.JSONArray;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

import com.csw.data.nvd.audit.NvdJobStatusEnumeration;
import com.csw.data.nvd.audit.NvdParserAudit;
import com.csw.data.nvd.audit.RecordDetails;
import com.csw.data.nvd.config.ParseType;
import com.csw.data.nvd.json.cpe.source.DefCpeMatch;
import com.csw.data.nvd.json.targets.VendorComment;
import com.csw.data.nvd.json.targets.Vulnerability;
import com.csw.data.nvd.parser.CommonVulnerabilityExtractor;
import com.csw.data.nvd.parser.CveProcessor;
import com.csw.data.nvd.parser.TopicProcessor;
import com.csw.data.nvd.service.LiveKeepService;
import com.csw.data.util.CommonUtils;
import com.csw.data.util.ParserConstants;
import com.csw.data.util.ParserFileUtils;
import com.fasterxml.jackson.databind.ObjectMapper;

@Service
@Qualifier("CommonVulnerabilityExtractor")
public class CommonVulnerabilityExtractorImpl implements CommonVulnerabilityExtractor {

    private static final Logger LOGGER = LoggerFactory.getLogger(CommonVulnerabilityExtractorImpl.class);

    @Value("#{'${parser.cve.download.latest.url}'.split(',')}")
    private List<String> cveSourceDirectoryLatest;

    @Value("#{'${parser.cve.download.url}'.split(',')}")
    private List<String> cveDownloadUrls;

    @Value("${parser.vendorcomments.download.url}")
    private List<String> vendorCommentUrls;
    
    @Value("#{'${parser.cpe.download.url}'.split(',')}")
    private List<String> cpeDownloadUrls;

    @Value("${parser.cve.source.directory}")
    private String cveSourceDirectory;

    @Value("${parser.cve.local.directory}")
    private String cveLocalDirectory;
    
    @Value("${parser.cpe.source.directory}")
    private String cpeSourceDirectory;

    @Value("${parser.cpe.local.directory}")
    private String cpeLocalDirectory;

    @Autowired
    private CveProcessor cveProcessor;
    
    @Autowired
    private TopicProcessor<DefCpeMatch> cpeProcessor;

    @Autowired
    private LiveKeepService<Vulnerability> liveKeepService;
    
    @Autowired
    private LiveKeepService<DefCpeMatch> cpeLiveKeepServiceImpl;

    /** The kafka template. */
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;

    /** The kafka topic. */
    @Value("${data.kafka.topic}")
    private String kafkaTopic;

    @Override
    public void parseCve(boolean processLatest) throws IOException {
        LOGGER.info("started parsing CVE..");
        
        // download and extract cve source files and process every files
        List<String> cveSourceUrl = getSourceUrl(processLatest);
        List<String> sourceFiles = ParserFileUtils.extractSourceFilesWithExtension(cveSourceDirectory, cveSourceUrl, ParseType.CVE.name(), ParserConstants.JSON_FILE_EXTENSION);
        LOGGER.info("sourceFiles : {}", sourceFiles);
        
        // extract vendor comments from NVD
        Map<String, List<VendorComment>> vendorComments = cveProcessor.extractVendorComments(vendorCommentUrls);
        
        for (String sourceFile : sourceFiles) {
            // record the parser start time
            LocalDateTime startTime = LocalDateTime.now();
            
            // process vulnerabilities from the source file
            List<Vulnerability> vulnerabilities = cveProcessor.extractVulnerabilitiesFromSource(sourceFile, vendorComments);

            // write the file to livekeep and return kafka message
            Map<String, Integer> recordStats = initializeRecordStatMap();
            JSONArray kafkaMessage = liveKeepService.writeFileToLiveKeep(vulnerabilities, cveLocalDirectory, recordStats);
            List<JSONArray> kafkaMessagePartioned = CommonUtils.splitJsonArrayByChunkLimit(kafkaMessage, 1000);
            
            // push the message to kafka topic
            for (JSONArray message : kafkaMessagePartioned) {
                try {
                    kafkaTemplate.send(kafkaTopic, message.toString()).get();
                }
                catch (Exception e) {
                    LOGGER.info("Error while sending the message");
                }
            }
            
            //update the final job audit
            LocalDateTime endTime = LocalDateTime.now();
            NvdParserAudit audit = logAudit(vulnerabilities.size(), startTime, endTime, recordStats);
            ObjectMapper logMapper = new ObjectMapper();
            String jobAudit = logMapper.writeValueAsString(audit);
            LOGGER.info("Job Audit : {}", jobAudit);
        }
        LOGGER.info("CVE data process completed..");
    }
    
    @Override
    public void parseCpe() throws IOException {
        
        // download and extract cve source files and process every files
        List<String> cpeSourceFiles = ParserFileUtils.extractSourceFilesWithExtension(cpeSourceDirectory, cpeDownloadUrls, ParseType.CPE.name(), ParserConstants.JSON_FILE_EXTENSION);
        
        for (String cpeSourceFile : cpeSourceFiles) {
            
            LocalDateTime startTime = LocalDateTime.now();
            
            //unmarshall the cpeSourceFile
            List<DefCpeMatch> defCpeMatchs = cpeProcessor.unmarshallObjectFromSourceFile(cpeSourceFile);
            
            //write the cpe file and meta file to livekeep and create kafka message
            Map<String, Integer> recordStats = initializeRecordStatMap();
            JSONArray kafkaMessage = cpeLiveKeepServiceImpl.writeFileToLiveKeep(defCpeMatchs, cpeLocalDirectory, recordStats);
            List<JSONArray> kafkaMessagePartioned = CommonUtils.splitJsonArrayByChunkLimit(kafkaMessage, 1000);
            
            LOGGER.info("kafkaMessage size: {}", kafkaMessage.length());
            LOGGER.info("kafkaMessagePartioned size: {}", kafkaMessagePartioned.size());
            
            //publish the kafka message
            /**
            for (JSONArray message : kafkaMessagePartioned) {
                try {
                    kafkaTemplate.send(kafkaTopic, message.toString()).get();
                }
                catch (Exception e) {
                    LOGGER.info("Error while sending the message");
                }
            }
            **/
            
            //audit logs or this job
            LocalDateTime endTime = LocalDateTime.now();
            NvdParserAudit audit = logAudit(defCpeMatchs.size(), startTime, endTime, recordStats);
            ObjectMapper logMapper = new ObjectMapper();
            String jobAudit = logMapper.writeValueAsString(audit);
            LOGGER.info("Job Audit : {}", jobAudit);
        }
        
    }
    
    private List<String> getSourceUrl(boolean processLatest) {
        if (processLatest) {
            return cveSourceDirectoryLatest;
        }
        else {
            return cveDownloadUrls;
        }
    }
    
    private NvdParserAudit logAudit(int totalRecords, LocalDateTime startTime, LocalDateTime endTime, Map<String, Integer> recordStats) {
        NvdParserAudit audit = new NvdParserAudit();
        DateTimeFormatter auditTimeFormat = DateTimeFormatter.ofPattern("uuuu/MM/dd HH:mm:ss");
        Long jobStartTime = TimeUnit.MILLISECONDS.toSeconds(Timestamp.valueOf(startTime).getTime()); 
        Long jobEndTime = TimeUnit.MILLISECONDS.toSeconds(Timestamp.valueOf(endTime).getTime());

        RecordDetails recordDetails = new RecordDetails();
        recordDetails.setTotalRecords(totalRecords);
        recordDetails.setNewRecords(recordStats.get("newRecords"));
        recordDetails.setModifiedRecords(recordStats.get("modifiedRecords"));

        audit.setJobName("NVD CVE Parser");
        audit.setRefreshType("Full Refresh");
        audit.setStartTime(auditTimeFormat.format(startTime));
        audit.setEndTime(auditTimeFormat.format(endTime));
        audit.setTotalTime(String.valueOf(jobEndTime - jobStartTime));
        audit.setRecordDetails(recordDetails);
        audit.setJobStatus(NvdJobStatusEnumeration.COMPLETED);
        return audit;
    }

    /**
     * Initialize record stat map.
     *
     * @return the map
     */
    private Map<String, Integer> initializeRecordStatMap() {
        Map<String, Integer> recordsStatMap = new HashMap<>();
        recordsStatMap.put("newRecords", 0);
        recordsStatMap.put("modifiedRecords", 0);
        recordsStatMap.put("failedRecords", 0);
        return recordsStatMap;
    }

}
